{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "adsdevsynspads",
              "session_id": 6,
              "statement_id": 1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-07-06T23:10:33.0611961Z",
              "session_start_time": "2022-07-06T23:10:33.0987283Z",
              "execution_start_time": "2022-07-06T23:13:16.0131615Z",
              "execution_finish_time": "2022-07-06T23:13:16.1654383Z"
            },
            "text/plain": "StatementMeta(adsdevsynspads, 6, 1, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": [
          "parameters"
        ]
      },
      "source": [
        "StorageAccountName = \"adsdevdlsadsalfsadsl\"\r\n",
        "StorageAccountContainer = \"datalakeraw\"\r\n",
        "StorageAccountFolder = \"/samples/sif/\"\r\n",
        "SifDbName = \"sif\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Persist Codesets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "adsdevsynspads",
              "session_id": 1,
              "statement_id": 16,
              "state": "finished",
              "livy_statement_state": "cancelled",
              "queued_time": "2022-07-06T10:38:02.0910835Z",
              "session_start_time": null,
              "execution_start_time": "2022-07-06T10:38:02.4142345Z",
              "execution_finish_time": "2022-07-06T10:38:10.9177731Z"
            },
            "text/plain": "StatementMeta(adsdevsynspads, 1, 16, Finished, Cancelled)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "import json\r\n",
        "dict1 = json.loads('{\"StorageAccountName\": \"' + StorageAccountName + '\", \"StorageAccountContainer\":\"' + StorageAccountContainer + '\", \"StorageAccountFolder\": \"'+StorageAccountFolder+'SifOpenApi/\", \"SifDbName\":\"' + SifDbName + '\"}')\r\n",
        "dict2 = json.dumps(dict1)\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFLoadCodeSets\", 900,dict1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Declare Function to Create TaskObject**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "adsdevsynspads",
              "session_id": 5,
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-07-06T11:06:55.2486803Z",
              "session_start_time": null,
              "execution_start_time": "2022-07-06T11:06:55.3672056Z",
              "execution_finish_time": "2022-07-06T11:06:55.5494922Z"
            },
            "text/plain": "StatementMeta(adsdevsynspads, 5, 4, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def RunDimNoteBook(StorageAccountName, Entity):\r\n",
        "    OutputDict = {}\r\n",
        "    TaskObject = \"{\\\"TaskInstanceId\\\":53,\\\"TaskMasterId\\\":1,\\\"TaskStatus\\\":\\\"InProgress\\\",\\\"TaskType\\\":\\\"Execute Synapse Notebook\\\",\\\"Enabled\\\":1,\\\"ExecutionUid\\\":\\\"dc872650-b992-4cae-9ae2-c714c95563ee\\\",\\\"NumberOfRetries\\\":2,\\\"DegreeOfCopyParallelism\\\":1, \\\"KeyVaultBaseUrl\\\":\\\"https://ads-dev-kv-ads-tad5.vault.azure.net/\\\",\\\"ScheduleMasterId\\\":\\\"-4\\\",\\\"TaskGroupConcurrency\\\":\\\"10\\\",\\\"TaskGroupPriority\\\":0,\\\"TaskExecutionType\\\":\\\"ADF\\\",\\\"Source\\\":{\\\"System\\\":{\\\"SystemId\\\":-4, \\\"SystemServer\\\":\\\"https://\"+StorageAccountName+\".dfs.core.windows.net\\\",\\\"AuthenticationType\\\":\\\"MSI\\\",\\\"Type\\\":\\\"ADLS\\\",\\\"Username\\\":null,\\\"Container\\\":\\\"datalakeraw\\\"},\\\"Instance\\\":{\\\"SourceRelativePath\\\":\\\"/samples/sif/\\\",  \\\"TargetRelativePath\\\":\\\"/samples/sif/\"+Entity+\"/\\\"},\\\"DataFileName\\\":\\\"\"+Entity+\".json\\\",\\\"RelativePath\\\":\\\"/samples/sif/\\\",\\\"SchemaFileName\\\":\\\"\\\",\\\"Type\\\":\\\"Notebook-Optional\\\",\\\"WriteSchemaToPurview\\\":\\\"Disabled\\\"}, \\\"Target\\\":{\\\"System\\\":{\\\"SystemId\\\":-4,\\\"SystemServer\\\":\\\"https://\"+StorageAccountName+\".dfs.core.windows.net\\\",\\\"AuthenticationType\\\":\\\"MSI\\\",\\\"Type\\\":\\\"ADLS\\\",\\\"Username\\\":null,\\\"Container\\\":\\\"datalakeraw\\\"},\\\"Instance\\\":{\\\"SourceRelativePath\\\":\\\"/samples/sif/\\\",\\\"TargetRelativePath\\\":\\\"/samples/sif/\"+Entity+\"/\\\"},\\\"DataFileName\\\":\\\"\"+Entity+\".parquet\\\",\\\"RelativePath\\\":\\\"/samples/sif/\"+Entity+\"/\\\", \\\"SchemaFileName\\\":\\\"\\\",\\\"Type\\\":\\\"Notebook-Optional\\\",\\\"WriteSchemaToPurview\\\":\\\"Disabled\\\"},\\\"TMOptionals\\\":{\\\"CustomDefinitions\\\":\\\"\\\",\\\"ExecuteNotebook\\\":\\\"SIFParameterizedJson\\\",\\\"Purview\\\":\\\"Disabled\\\", \\\"QualifiedIDAssociation\\\":\\\"TaskMasterId\\\",\\\"UseNotebookActivity\\\":\\\"Enabled\\\"}}\"\r\n",
        "    OutputDict['TaskObject'] = TaskObject\r\n",
        "    mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Generate Task Object and Execute Delta Lake Load for Each Raw SIF Entity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "adsdevsynspads",
              "session_id": 5,
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-07-06T11:06:58.1092256Z",
              "session_start_time": null,
              "execution_start_time": "2022-07-06T11:06:58.2080263Z",
              "execution_finish_time": "2022-07-06T11:12:57.106434Z"
            },
            "text/plain": "StatementMeta(adsdevsynspads, 5, 5, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "25b81e36-998c-40c4-9463-8d75d0cf9679",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/25b81e36-998c-40c4-9463-8d75d0cf9679/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "dc5c62bd-5528-44ca-88fa-5c6bc0b38103",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/dc5c62bd-5528-44ca-88fa-5c6bc0b38103/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "4f112c13-9eb9-4627-845c-c17415af6d85",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/4f112c13-9eb9-4627-845c-c17415af6d85/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "2a444cb2-1849-44fe-b96a-4c3c9328bdc0",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/2a444cb2-1849-44fe-b96a-4c3c9328bdc0/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "3a3e3dcd-bb69-4ae6-91a1-5137d6d3103c",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/3a3e3dcd-bb69-4ae6-91a1-5137d6d3103c/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "8344545e-1b6c-4cc0-9ff4-9ab855d1fdfa",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/8344545e-1b6c-4cc0-9ff4-9ab855d1fdfa/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "983469aa-ef86-42b7-b115-7fa794edf289",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/983469aa-ef86-42b7-b115-7fa794edf289/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "9fa91fee-cf2b-4651-b5a8-33999e377cc2",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/9fa91fee-cf2b-4651-b5a8-33999e377cc2/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "1ae6cde2-fe93-4a3b-ad9f-dddca6935901",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/1ae6cde2-fe93-4a3b-ad9f-dddca6935901/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "522426dc-30b4-45b9-bd49-81a5ff4f380d",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/522426dc-30b4-45b9-bd49-81a5ff4f380d/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "07092883-8896-411a-9a2c-b242307f7001",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/07092883-8896-411a-9a2c-b242307f7001/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "4af25917-d5c3-41ef-be63-4ca68c75f2c0",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/4af25917-d5c3-41ef-be63-4ca68c75f2c0/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "526dd986-c705-4837-a6ce-f0adff7e6a30",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/526dd986-c705-4837-a6ce-f0adff7e6a30/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "86715299-2d64-4646-bcc0-1523897c54a3",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/86715299-2d64-4646-bcc0-1523897c54a3/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "b347b391-17f5-4589-aaef-169261e4f0c7",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/b347b391-17f5-4589-aaef-169261e4f0c7/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "e30c9f8c-36e2-486b-8257-ea468ec83c5e",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/e30c9f8c-36e2-486b-8257-ea468ec83c5e/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "8dfa8ef2-a9cf-4042-b312-5bc331d961ff",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/8dfa8ef2-a9cf-4042-b312-5bc331d961ff/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "57f99bef-00d9-4778-aac8-547449d56e4c",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/57f99bef-00d9-4778-aac8-547449d56e4c/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "9ec96898-c8ad-4216-803b-61fee731da1c",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/9ec96898-c8ad-4216-803b-61fee731da1c/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "7219b5b6-bae3-4860-8533-502263e156b1",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/7219b5b6-bae3-4860-8533-502263e156b1/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "8ed266bd-ca22-4fdd-a317-f2386f75fa09",
              "in_pipeline": false,
              "notebook_name": "SIFParameterizedJson",
              "snapshot_path": "/runNotebookApi/versions/1/run/8ed266bd-ca22-4fdd-a317-f2386f75fa09/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling o600.throwExceptionIfHave.\n: com.microsoft.spark.notebook.msutils.NotebookExecutionException: abfss://datalakeraw@adsdevdlsadsalfsadsl.dfs.core.windows.net/samples/sif/CalendarDate/CalendarDate.parquet already exists.;\n---------------------------------------------------------------------------Py4JJavaError                             Traceback (most recent call last)/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py in deco(*a, **kw)\n     68         try:\n---> 69             return f(*a, **kw)\n     70         except py4j.protocol.Py4JJavaError as e:\n/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)\n    327                     \"An error occurred while calling {0}{1}{2}.\\n\".\n--> 328                     format(target_id, \".\", name), value)\n    329             else:\nPy4JJavaError: An error occurred while calling o601.execute.\n: org.apache.spark.sql.AnalysisException: cannot resolve `oldData.RefId` in search condition given columns oldData.`CalendarDateRefId`, oldData.`CalendarDateType`, oldData.`CalendarSummaryRefId`, oldData.`Date`, oldData.`SchoolInfoRefId`, oldData.`SchoolYear`, oldData.`StudentAttendance`, oldData.`TeacherAttendance`, newData.`CalendarDateRefId`, newData.`CalendarDateType`, newData.`CalendarSummaryRefId`, newData.`Date`, newData.`SchoolInfoRefId`, newData.`SchoolYear`, newData.`StudentAttendance`, newData.`TeacherAttendance`; line 1 pos 0\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.DeltaMergeInto$$anonfun$org$apache$spark$sql$catalyst$plans$logical$DeltaMergeInto$$resolveExprsOrFail$1$3.apply(deltaMerge.scala:262)\n\tat org.apache.spark.sql.catalyst.plans.logical.DeltaMergeInto$$anonfun$org$apache$spark$sql$catalyst$plans$logical$DeltaMergeInto$$resolveExprsOrFail$1$3.apply(deltaMerge.scala:258)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.plans.logical.DeltaMergeInto$.org$apache$spark$sql$catalyst$plans$logical$DeltaMergeInto$$resolveExprsOrFail$1(deltaMerge.scala:258)\n\tat org.apache.spark.sql.catalyst.plans.logical.DeltaMergeInto$.org$apache$spark$sql$catalyst$plans$logical$DeltaMergeInto$$resolveOrFail$1(deltaMerge.scala:271)\n\tat org.apache.spark.sql.catalyst.plans.logical.DeltaMergeInto$.resolveReferences(deltaMerge.scala:394)\n\tat io.delta.tables.DeltaMergeBuilder.execute(DeltaMergeBuilder.scala:228)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDuring handling of the above exception, another exception occurred:\nAnalysisException                         Traceback (most recent call last)<ipython-input-9-8fd5a094da81> in <module>\n     22             df.alias(\"newData\"),\n---> 23             mergeCondition) \\\n     24         .whenMatchedUpdateAll() \\\n/usr/hdp/current/spark2-client/jars/delta-core_2.11-0.6.1.11.jar/delta/tables.py in execute(self)\n    691         \"\"\"\n--> 692         self._jbuilder.execute()\n    693 \n/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py in __call__(self, *args)\n   1256         return_value = get_return_value(\n-> 1257             answer, self.gateway_client, self.target_id, self.name)\n   1258 \n/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py in deco(*a, **kw)\n     74             if s.startswith('org.apache.spark.sql.AnalysisException: '):\n---> 75                 raise AnalysisException(s.split(': ', 1)[1], stackTrace)\n     76             if s.startswith('org.apache.spark.sql.catalyst.analysis'):\nAnalysisException: cannot resolve `oldData.RefId` in search condition given columns oldData.`CalendarDateRefId`, oldData.`CalendarDateType`, oldData.`CalendarSummaryRefId`, oldData.`Date`, oldData.`SchoolInfoRefId`, oldData.`SchoolYear`, oldData.`StudentAttendance`, oldData.`TeacherAttendance`, newData.`CalendarDateRefId`, newData.`CalendarDateType`, newData.`CalendarSummaryRefId`, newData.`Date`, newData.`SchoolInfoRefId`, newData.`SchoolYear`, newData.`StudentAttendance`, newData.`TeacherAttendance`; line 1 pos 0\nDuring handling of the above exception, another exception occurred:\nPy4JJavaError                             Traceback (most recent call last)/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py in deco(*a, **kw)\n     68         try:\n---> 69             return f(*a, **kw)\n     70         except py4j.protocol.Py4JJavaError as e:\n/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)\n    327                     \"An error occurred while calling {0}{1}{2}.\\n\".\n--> 328                     format(target_id, \".\", name), value)\n    329             else:\nPy4JJavaError: An error occurred while calling o624.save.\n: org.apache.spark.sql.AnalysisException: abfss://datalakeraw@adsdevdlsadsalfsadsl.dfs.core.windows.net/samples/sif/CalendarDate/CalendarDate.parquet already exists.;\n\tat org.apache.spark.sql.delta.DeltaErrors$.pathAlreadyExistsException(DeltaErrors.scala:362)\n\tat org.apache.spark.sql.delta.commands.WriteIntoDelta.write(WriteIntoDelta.scala:77)\n\tat org.apache.spark.sql.delta.commands.WriteIntoDelta$$anonfun$run$1.apply(WriteIntoDelta.scala:65)\n\tat org.apache.spark.sql.delta.commands.WriteIntoDelta$$anonfun$run$1.apply(WriteIntoDelta.scala:64)\n\tat org.apache.spark.sql.delta.DeltaLog.withNewTransaction(DeltaLog.scala:190)\n\tat org.apache.spark.sql.delta.commands.WriteIntoDelta.run(WriteIntoDelta.scala:64)\n\tat org.apache.spark.sql.delta.sources.DeltaDataSource.createRelation(DeltaDataSource.scala:134)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:45)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:86)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:157)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:153)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:181)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:178)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:153)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:109)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:107)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:702)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:702)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:90)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:144)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:80)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:702)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:306)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:292)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:250)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDuring handling of the above exception, another exception occurred:\nAnalysisException                         Traceback (most recent call last)<ipython-input-9-8fd5a094da81> in <module>\n     30 except:\n     31     print(\"Table does not exist. Creating new Delta Table.\")    \n---> 32     df.write.format(\"Delta\").save(Target)\n/opt/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py in save(self, path, format, mode, partitionBy, **options)\n    740             self._jwrite.save()\n    741         else:\n--> 742             self._jwrite.save(path)\n    743 \n    744     @since(1.4)\n/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py in __call__(self, *args)\n   1255         answer = self.gateway_client.send_command(command)\n   1256         return_value = get_return_value(\n-> 1257             answer, self.gateway_client, self.target_id, self.name)\n   1258 \n   1259         for temp_arg in temp_args:\n/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py in deco(*a, **kw)\n     73                                              e.java_exception.getStackTrace()))\n     74             if s.startswith('org.apache.spark.sql.AnalysisException: '):\n---> 75                 raise AnalysisException(s.split(': ', 1)[1], stackTrace)\n     76             if s.startswith('org.apache.spark.sql.catalyst.analysis'):\n     77                 raise AnalysisException(s.split(': ', 1)[1], stackTrace)\nAnalysisException: abfss://datalakeraw@adsdevdlsadsalfsadsl.dfs.core.windows.net/samples/sif/CalendarDate/CalendarDate.parquet already exists.;You can check driver log or snapshot for detailed error info! See how to check logs: https://go.microsoft.com/fwlink/?linkid=2157243.\n\tat com.microsoft.spark.notebook.workflow.JobSessionClient.com$microsoft$spark$notebook$workflow$JobSessionClient$$runCell(JobSessionClient.scala:148)\n\tat com.microsoft.spark.notebook.workflow.JobSessionClient$$anonfun$run$2.apply(JobSessionClient.scala:69)\n\tat com.microsoft.spark.notebook.workflow.JobSessionClient$$anonfun$run$2.apply(JobSessionClient.scala:60)\n\tat scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)\n\tat com.microsoft.spark.notebook.workflow.JobSessionClient.run(JobSessionClient.scala:60)\n\tat com.microsoft.spark.notebook.msutils.impl.MSNotebookUtilsImpl._run(MSNotebookUtilsImpl.scala:138)\n\tat com.microsoft.spark.notebook.msutils.impl.MSNotebookUtilsImpl.run(MSNotebookUtilsImpl.scala:171)\n\tat mssparkutils.notebook$.run(notebook.scala:45)\n\tat mssparkutils.notebook.run(notebook.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-8d275ec7c3a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mThreadPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThreadPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRunDimNoteBook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStorageAccountName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/cluster-env/env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/cluster-env/env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/cluster-env/env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/cluster-env/env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmapstar\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-8d275ec7c3a7>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mThreadPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThreadPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRunDimNoteBook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStorageAccountName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-6c3ccc5b9fdd>\u001b[0m in \u001b[0;36mRunDimNoteBook\u001b[0;34m(StorageAccountName, Entity)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mTaskObject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{\\\"TaskInstanceId\\\":53,\\\"TaskMasterId\\\":1,\\\"TaskStatus\\\":\\\"InProgress\\\",\\\"TaskType\\\":\\\"Execute Synapse Notebook\\\",\\\"Enabled\\\":1,\\\"ExecutionUid\\\":\\\"dc872650-b992-4cae-9ae2-c714c95563ee\\\",\\\"NumberOfRetries\\\":2,\\\"DegreeOfCopyParallelism\\\":1, \\\"KeyVaultBaseUrl\\\":\\\"https://ads-dev-kv-ads-tad5.vault.azure.net/\\\",\\\"ScheduleMasterId\\\":\\\"-4\\\",\\\"TaskGroupConcurrency\\\":\\\"10\\\",\\\"TaskGroupPriority\\\":0,\\\"TaskExecutionType\\\":\\\"ADF\\\",\\\"Source\\\":{\\\"System\\\":{\\\"SystemId\\\":-4, \\\"SystemServer\\\":\\\"https://\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mStorageAccountName\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".dfs.core.windows.net\\\",\\\"AuthenticationType\\\":\\\"MSI\\\",\\\"Type\\\":\\\"ADLS\\\",\\\"Username\\\":null,\\\"Container\\\":\\\"datalakeraw\\\"},\\\"Instance\\\":{\\\"SourceRelativePath\\\":\\\"/samples/sif/\\\",  \\\"TargetRelativePath\\\":\\\"/samples/sif/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mEntity\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\\\"},\\\"DataFileName\\\":\\\"\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mEntity\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".json\\\",\\\"RelativePath\\\":\\\"/samples/sif/\\\",\\\"SchemaFileName\\\":\\\"\\\",\\\"Type\\\":\\\"Notebook-Optional\\\",\\\"WriteSchemaToPurview\\\":\\\"Disabled\\\"}, \\\"Target\\\":{\\\"System\\\":{\\\"SystemId\\\":-4,\\\"SystemServer\\\":\\\"https://\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mStorageAccountName\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".dfs.core.windows.net\\\",\\\"AuthenticationType\\\":\\\"MSI\\\",\\\"Type\\\":\\\"ADLS\\\",\\\"Username\\\":null,\\\"Container\\\":\\\"datalakeraw\\\"},\\\"Instance\\\":{\\\"SourceRelativePath\\\":\\\"/samples/sif/\\\",\\\"TargetRelativePath\\\":\\\"/samples/sif/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mEntity\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\\\"},\\\"DataFileName\\\":\\\"\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mEntity\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".parquet\\\",\\\"RelativePath\\\":\\\"/samples/sif/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mEntity\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\\\", \\\"SchemaFileName\\\":\\\"\\\",\\\"Type\\\":\\\"Notebook-Optional\\\",\\\"WriteSchemaToPurview\\\":\\\"Disabled\\\"},\\\"TMOptionals\\\":{\\\"CustomDefinitions\\\":\\\"\\\",\\\"ExecuteNotebook\\\":\\\"SIFParameterizedJson\\\",\\\"Purview\\\":\\\"Disabled\\\", \\\"QualifiedIDAssociation\\\":\\\"TaskMasterId\\\",\\\"UseNotebookActivity\\\":\\\"Enabled\\\"}}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mOutputDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TaskObject'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTaskObject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmssparkutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FrameworkNotebooks/sif/SIFParameterizedJson\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m900\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/cluster-env/env/lib/python3.6/site-packages/notebookutils/mssparkutils/notebook.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(path, timeout_seconds, arguments)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_seconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mexit_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_seconds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexit_val\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTOP_SESSION_REQUEST_EXIT_VAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/cluster-env/env/lib/python3.6/site-packages/notebookutils/mssparkutils/handlers/notebookHandler.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, path, timeout_seconds, arguments)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mrun_result_snapshot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj_notebook_run_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnapshotMetaStr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_result_snapshot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mj_notebook_run_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrowExceptionIfHave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexit_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o600.throwExceptionIfHave.\n: com.microsoft.spark.notebook.msutils.NotebookExecutionException: abfss://datalakeraw@adsdevdlsadsalfsadsl.dfs.core.windows.net/samples/sif/CalendarDate/CalendarDate.parquet already exists.;\n---------------------------------------------------------------------------Py4JJavaError                             Traceback (most recent call last)/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py in deco(*a, **kw)\n     68         try:\n---> 69             return f(*a, **kw)\n     70         except py4j.protocol.Py4JJavaError as e:\n/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)\n    327                     \"An error occurred while calling {0}{1}{2}.\\n\".\n--> 328                     format(target_id, \".\", name), value)\n    329             else:\nPy4JJavaError: An error occurred while calling o601.execute.\n: org.apache.spark.sql.AnalysisException: cannot resolve `oldData.RefId` in search condition given columns oldData.`CalendarDateRefId`, oldData.`CalendarDateType`, oldData.`CalendarSummaryRefId`, oldData.`Date`, oldData.`SchoolInfoRefId`, oldData.`SchoolYear`, oldData.`StudentAttendance`, oldData.`TeacherAttendance`, newData.`CalendarDateRefId`, newData.`CalendarDateType`, newData.`CalendarSummaryRefId`, newData.`Date`, newData.`SchoolInfoRefId`, newData.`SchoolYear`, newData.`StudentAttendance`, newData.`TeacherAttendance`; line 1 pos 0\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.plans.logical.DeltaMergeInto$$anonfun$org$apache$spark$sql$catalyst$plans$logical$DeltaMergeInto$$resolveExprsOrFail$1$3.apply(deltaMerge.scala:262)\n\tat org.apache.spark.sql.catalyst.plans.logical.DeltaMergeInto$$anonfun$org$apache$spark$sql$catalyst$plans$logical$DeltaMergeInto$$resolveExprsOrFail$1$3.apply(deltaMerge.scala:258)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.plans.logical.DeltaMergeInto$.org$apache$spark$sql$catalyst$plans$logical$DeltaMergeInto$$resolveExprsOrFail$1(deltaMerge.scala:258)\n\tat org.apache.spark.sql.catalyst.plans.logical.DeltaMergeInto$.org$apache$spark$sql$catalyst$plans$logical$DeltaMergeInto$$resolveOrFail$1(deltaMerge.scala:271)\n\tat org.apache.spark.sql.catalyst.plans.logical.DeltaMergeInto$.resolveReferences(deltaMerge.scala:394)\n\tat io.delta.tables.DeltaMergeBuilder.execute(DeltaMergeBuilder.scala:228)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDuring handling of the above exception, another exception occurred:\nAnalysisException                         Traceback (most recent call last)<ipython-input-9-8fd5a094da81> in <module>\n     22             df.alias(\"newData\"),\n---> 23             mergeCondition) \\\n     24         .whenMatchedUpdateAll() \\\n/usr/hdp/current/spark2-client/jars/delta-core_2.11-0.6.1.11.jar/delta/tables.py in execute(self)\n    691         \"\"\"\n--> 692         self._jbuilder.execute()\n    693 \n/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py in __call__(self, *args)\n   1256         return_value = get_return_value(\n-> 1257             answer, self.gateway_client, self.target_id, self.name)\n   1258 \n/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py in deco(*a, **kw)\n     74             if s.startswith('org.apache.spark.sql.AnalysisException: '):\n---> 75                 raise AnalysisException(s.split(': ', 1)[1], stackTrace)\n     76             if s.startswith('org.apache.spark.sql.catalyst.analysis'):\nAnalysisException: cannot resolve `oldData.RefId` in search condition given columns oldData.`CalendarDateRefId`, oldData.`CalendarDateType`, oldData.`CalendarSummaryRefId`, oldData.`Date`, oldData.`SchoolInfoRefId`, oldData.`SchoolYear`, oldData.`StudentAttendance`, oldData.`TeacherAttendance`, newData.`CalendarDateRefId`, newData.`CalendarDateType`, newData.`CalendarSummaryRefId`, newData.`Date`, newData.`SchoolInfoRefId`, newData.`SchoolYear`, newData.`StudentAttendance`, newData.`TeacherAttendance`; line 1 pos 0\nDuring handling of the above exception, another exception occurred:\nPy4JJavaError                             Traceback (most recent call last)/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py in deco(*a, **kw)\n     68         try:\n---> 69             return f(*a, **kw)\n     70         except py4j.protocol.Py4JJavaError as e:\n/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)\n    327                     \"An error occurred while calling {0}{1}{2}.\\n\".\n--> 328                     format(target_id, \".\", name), value)\n    329             else:\nPy4JJavaError: An error occurred while calling o624.save.\n: org.apache.spark.sql.AnalysisException: abfss://datalakeraw@adsdevdlsadsalfsadsl.dfs.core.windows.net/samples/sif/CalendarDate/CalendarDate.parquet already exists.;\n\tat org.apache.spark.sql.delta.DeltaErrors$.pathAlreadyExistsException(DeltaErrors.scala:362)\n\tat org.apache.spark.sql.delta.commands.WriteIntoDelta.write(WriteIntoDelta.scala:77)\n\tat org.apache.spark.sql.delta.commands.WriteIntoDelta$$anonfun$run$1.apply(WriteIntoDelta.scala:65)\n\tat org.apache.spark.sql.delta.commands.WriteIntoDelta$$anonfun$run$1.apply(WriteIntoDelta.scala:64)\n\tat org.apache.spark.sql.delta.DeltaLog.withNewTransaction(DeltaLog.scala:190)\n\tat org.apache.spark.sql.delta.commands.WriteIntoDelta.run(WriteIntoDelta.scala:64)\n\tat org.apache.spark.sql.delta.sources.DeltaDataSource.createRelation(DeltaDataSource.scala:134)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:45)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:86)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:157)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:153)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:181)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:178)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:153)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:109)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:107)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:702)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:702)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:90)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:144)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:80)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:702)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:306)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:292)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:250)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDuring handling of the above exception, another exception occurred:\nAnalysisException                         Traceback (most recent call last)<ipython-input-9-8fd5a094da81> in <module>\n     30 except:\n     31     print(\"Table does not exist. Creating new Delta Table.\")    \n---> 32     df.write.format(\"Delta\").save(Target)\n/opt/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py in save(self, path, format, mode, partitionBy, **options)\n    740             self._jwrite.save()\n    741         else:\n--> 742             self._jwrite.save(path)\n    743 \n    744     @since(1.4)\n/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py in __call__(self, *args)\n   1255         answer = self.gateway_client.send_command(command)\n   1256         return_value = get_return_value(\n-> 1257             answer, self.gateway_client, self.target_id, self.name)\n   1258 \n   1259         for temp_arg in temp_args:\n/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py in deco(*a, **kw)\n     73                                              e.java_exception.getStackTrace()))\n     74             if s.startswith('org.apache.spark.sql.AnalysisException: '):\n---> 75                 raise AnalysisException(s.split(': ', 1)[1], stackTrace)\n     76             if s.startswith('org.apache.spark.sql.catalyst.analysis'):\n     77                 raise AnalysisException(s.split(': ', 1)[1], stackTrace)\nAnalysisException: abfss://datalakeraw@adsdevdlsadsalfsadsl.dfs.core.windows.net/samples/sif/CalendarDate/CalendarDate.parquet already exists.;You can check driver log or snapshot for detailed error info! See how to check logs: https://go.microsoft.com/fwlink/?linkid=2157243.\n\tat com.microsoft.spark.notebook.workflow.JobSessionClient.com$microsoft$spark$notebook$workflow$JobSessionClient$$runCell(JobSessionClient.scala:148)\n\tat com.microsoft.spark.notebook.workflow.JobSessionClient$$anonfun$run$2.apply(JobSessionClient.scala:69)\n\tat com.microsoft.spark.notebook.workflow.JobSessionClient$$anonfun$run$2.apply(JobSessionClient.scala:60)\n\tat scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)\n\tat com.microsoft.spark.notebook.workflow.JobSessionClient.run(JobSessionClient.scala:60)\n\tat com.microsoft.spark.notebook.msutils.impl.MSNotebookUtilsImpl._run(MSNotebookUtilsImpl.scala:138)\n\tat com.microsoft.spark.notebook.msutils.impl.MSNotebookUtilsImpl.run(MSNotebookUtilsImpl.scala:171)\n\tat mssparkutils.notebook$.run(notebook.scala:45)\n\tat mssparkutils.notebook.run(notebook.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "entities = [\"CalendarDate\" \\\r\n",
        ",\"GradingAssignment\" \\\r\n",
        ",\"GradingAssignmentScore\" \\\r\n",
        ",\"LearningStandardItem\" \\\r\n",
        ",\"MarkValueInfo\" \\\r\n",
        ",\"SchoolInfo2\" \\\r\n",
        ",\"SectionInfo\" \\\r\n",
        ",\"StaffAssignment\" \\\r\n",
        ",\"StaffPersonal\" \\\r\n",
        ",\"StudentContactPersonal\" \\\r\n",
        ",\"StudentContactRelationship\" \\\r\n",
        ",\"StudentDailyAttendance\" \\\r\n",
        ",\"StudentGrade\" \\\r\n",
        ",\"StudentPersonal\" \\\r\n",
        ",\"StudentSchoolEnrollment\" \\\r\n",
        ",\"StudentScoreJudgementAgainstStandard\" \\\r\n",
        ",\"StudentSectionEnrollment\" \\\r\n",
        ",\"TeachingGroup\" \\\r\n",
        ",\"TermInfo\" \\\r\n",
        ",\"TermInfo2\" \\\r\n",
        ",\"TermInfo3\" \\\r\n",
        ",\"schoolinfo\" \\\r\n",
        "]\r\n",
        "\r\n",
        "\r\n",
        "from multiprocessing.pool import ThreadPool\r\n",
        "pool = ThreadPool(5)\r\n",
        "pool.map(lambda e: RunDimNoteBook(StorageAccountName, e),entities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "adsdevsynspads",
              "session_id": 1,
              "statement_id": 18,
              "state": "finished",
              "livy_statement_state": "cancelled",
              "queued_time": "2022-07-06T10:38:02.2540222Z",
              "session_start_time": null,
              "execution_start_time": "2022-07-06T10:38:11.7866972Z",
              "execution_finish_time": "2022-07-06T10:38:14.2046216Z"
            },
            "text/plain": "StatementMeta(adsdevsynspads, 1, 18, Finished, Cancelled)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "OutputDict = {}\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"CalendarDate\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"GradingAssignment\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"GradingAssignmentScore\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"LearningStandardItem\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"MarkValueInfo\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"SchoolInfo2\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"SectionInfo\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"StaffAssignment\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"StaffPersonal\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"StudentContactPersonal\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"StudentContactRelationship\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"StudentDailyAttendance\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"StudentGrade\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"StudentPersonal\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"StudentSchoolEnrollment\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"StudentScoreJudgementAgainstStandard\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"StudentSectionEnrollment\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"TeachingGroup\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"TermInfo\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"TermInfo2\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"TermInfo3\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "OutputDict['TaskObject'] = GetTaskObject(StorageAccountName = StorageAccountName, Entity=\"schoolinfo\")\r\n",
        "mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFParameterizedJson\",900, OutputDict)\r\n",
        "\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Create SIF Dimensional Artefacts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "adsdevsynspads",
              "session_id": 5,
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-07-06T11:17:03.0427851Z",
              "session_start_time": null,
              "execution_start_time": "2022-07-06T11:17:03.1557786Z",
              "execution_finish_time": "2022-07-06T11:17:19.9348876Z"
            },
            "text/plain": "StatementMeta(adsdevsynspads, 5, 7, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "8eba97d2-c2e8-445e-8546-e8841e73a7a6",
              "in_pipeline": false,
              "notebook_name": "SIFLoadDimStaffPersonal",
              "snapshot_path": "/runNotebookApi/versions/1/run/8eba97d2-c2e8-445e-8546-e8841e73a7a6/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.mssparkutilsrun-result+json": {
              "run_id": "3838f4cc-12e9-4d57-9652-7c34517c93f0",
              "in_pipeline": false,
              "notebook_name": "SIFLoadDimStudentPersonal",
              "snapshot_path": "/runNotebookApi/versions/1/run/3838f4cc-12e9-4d57-9652-7c34517c93f0/snapshot",
              "error": null,
              "session_id": "5",
              "spark_pool": "adsdevsynspads"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling o825.throwExceptionIfHave.\n: com.microsoft.spark.notebook.msutils.NotebookExecutionException: name 'F' is not defined\n---------------------------------------------------------------------------NameError                                 Traceback (most recent call last)<ipython-input-6-da012f3f4c4a> in <module>\n      4 \n      5 df_Out = df_RawWJ \\\n----> 6 .withColumn('LocalId',F.when(for_exist_column(df_Raw, 'LocalId'), col('LocalId'))) \\\n      7 .withColumn('StateProvinceId',F.when(for_exist_column(df_Raw, 'StateProvinceId'), col('StateProvinceId'))) \\\n      8 .withColumn('FirstName',F.when(for_exist_column(df_Raw, 'PersonInfo.Name.GivenName'), col('PersonInfo.Name.GivenName'))) \\\nNameError: name 'F' is not definedYou can check driver log or snapshot for detailed error info! See how to check logs: https://go.microsoft.com/fwlink/?linkid=2157243.\n\tat com.microsoft.spark.notebook.workflow.JobSessionClient.com$microsoft$spark$notebook$workflow$JobSessionClient$$runCell(JobSessionClient.scala:148)\n\tat com.microsoft.spark.notebook.workflow.JobSessionClient$$anonfun$run$2.apply(JobSessionClient.scala:69)\n\tat com.microsoft.spark.notebook.workflow.JobSessionClient$$anonfun$run$2.apply(JobSessionClient.scala:60)\n\tat scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)\n\tat com.microsoft.spark.notebook.workflow.JobSessionClient.run(JobSessionClient.scala:60)\n\tat com.microsoft.spark.notebook.msutils.impl.MSNotebookUtilsImpl._run(MSNotebookUtilsImpl.scala:138)\n\tat com.microsoft.spark.notebook.msutils.impl.MSNotebookUtilsImpl.run(MSNotebookUtilsImpl.scala:171)\n\tat mssparkutils.notebook$.run(notebook.scala:45)\n\tat mssparkutils.notebook.run(notebook.scala)\n\tat sun.reflect.GeneratedMethodAccessor238.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-0ef40090649a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThreadPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mnotebooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'SIFLoadDimStaffPersonal'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SIFLoadDimStudentPersonal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmssparkutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/FrameworkNotebooks/sif/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_seconds\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnotebooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFLoadStaffPersonal\", 900,dict1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/cluster-env/env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/cluster-env/env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/cluster-env/env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/cluster-env/env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmapstar\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-0ef40090649a>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThreadPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mnotebooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'SIFLoadDimStaffPersonal'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SIFLoadDimStudentPersonal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmssparkutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/FrameworkNotebooks/sif/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_seconds\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnotebooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFLoadStaffPersonal\", 900,dict1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/cluster-env/env/lib/python3.6/site-packages/notebookutils/mssparkutils/notebook.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(path, timeout_seconds, arguments)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_seconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mexit_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_seconds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexit_val\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTOP_SESSION_REQUEST_EXIT_VAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/cluster-env/env/lib/python3.6/site-packages/notebookutils/mssparkutils/handlers/notebookHandler.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, path, timeout_seconds, arguments)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mrun_result_snapshot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj_notebook_run_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnapshotMetaStr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_result_snapshot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mj_notebook_run_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrowExceptionIfHave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexit_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o825.throwExceptionIfHave.\n: com.microsoft.spark.notebook.msutils.NotebookExecutionException: name 'F' is not defined\n---------------------------------------------------------------------------NameError                                 Traceback (most recent call last)<ipython-input-6-da012f3f4c4a> in <module>\n      4 \n      5 df_Out = df_RawWJ \\\n----> 6 .withColumn('LocalId',F.when(for_exist_column(df_Raw, 'LocalId'), col('LocalId'))) \\\n      7 .withColumn('StateProvinceId',F.when(for_exist_column(df_Raw, 'StateProvinceId'), col('StateProvinceId'))) \\\n      8 .withColumn('FirstName',F.when(for_exist_column(df_Raw, 'PersonInfo.Name.GivenName'), col('PersonInfo.Name.GivenName'))) \\\nNameError: name 'F' is not definedYou can check driver log or snapshot for detailed error info! See how to check logs: https://go.microsoft.com/fwlink/?linkid=2157243.\n\tat com.microsoft.spark.notebook.workflow.JobSessionClient.com$microsoft$spark$notebook$workflow$JobSessionClient$$runCell(JobSessionClient.scala:148)\n\tat com.microsoft.spark.notebook.workflow.JobSessionClient$$anonfun$run$2.apply(JobSessionClient.scala:69)\n\tat com.microsoft.spark.notebook.workflow.JobSessionClient$$anonfun$run$2.apply(JobSessionClient.scala:60)\n\tat scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)\n\tat com.microsoft.spark.notebook.workflow.JobSessionClient.run(JobSessionClient.scala:60)\n\tat com.microsoft.spark.notebook.msutils.impl.MSNotebookUtilsImpl._run(MSNotebookUtilsImpl.scala:138)\n\tat com.microsoft.spark.notebook.msutils.impl.MSNotebookUtilsImpl.run(MSNotebookUtilsImpl.scala:171)\n\tat mssparkutils.notebook$.run(notebook.scala:45)\n\tat mssparkutils.notebook.run(notebook.scala)\n\tat sun.reflect.GeneratedMethodAccessor238.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "import json\r\n",
        "from pyspark.sql.types import StructType,StructField, StringType,LongType\r\n",
        "from pyspark.sql.functions import concat,col\r\n",
        "\r\n",
        "\r\n",
        "#Schema = StructType([       \r\n",
        "#    StructField('Notebookname', StringType(), True)   \r\n",
        "#])\r\n",
        "\r\n",
        "dict1 = json.loads('{\"SifDbName\":\"' + SifDbName + '\"}')\r\n",
        "\r\n",
        "#Data = [[\"SIFLoadStaffPersonal\"],[\"SIFLoadStudentPersonal\"]]\r\n",
        "#df = spark.createDataFrame(data = Data, schema = [\"NotebookName\"])\r\n",
        "\r\n",
        "def fnc_calldimnotebook(NotebookName, dict1, returnType=StringType()):\r\n",
        "  NotebookName = concat('FrameworkNotebooks/sif/' + str(NotebookName))  \r\n",
        "  #mssparkutils.notebook.run(str(NotebookName), 900,dict1)\r\n",
        "  return NotebookName\r\n",
        "\r\n",
        "#spark.udf.register('fnc_calldimnotebook_udf', fnc_calldimnotebook, StringType())\r\n",
        "\r\n",
        "#df2 = df.withColumn(\"FncCall\", fnc_calldimnotebook(col('NotebookName'), dict1))\r\n",
        "#display(df2)\r\n",
        "\r\n",
        "from multiprocessing.pool import ThreadPool\r\n",
        "pool = ThreadPool(5)\r\n",
        "notebooks = ['SIFLoadDimStaffPersonal','SIFLoadDimStudentPersonal']\r\n",
        "pool.map(lambda path: mssparkutils.notebook.run(\"/FrameworkNotebooks/sif/\"+path, timeout_seconds= 600, arguments=dict1),notebooks)\r\n",
        "\r\n",
        "#mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFLoadStaffPersonal\", 900,dict1)\r\n",
        "#mssparkutils.notebook.run(\"FrameworkNotebooks/sif/SIFLoadStudentPersonal\", 900,dict1)\r\n",
        ""
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  }
}