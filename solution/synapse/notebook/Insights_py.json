{
	"name": "Insights_py",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "spark3p1sm",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "3e28e405-4bff-40e9-a0b4-53f8172a6f74"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/21fec1ab-7af8-4f99-b66f-a69e7ba77a22/resourceGroups/BCE-AAE-OEA-DEV-RG/providers/Microsoft.Synapse/workspaces/bce-aae-oea-dev-syn/bigDataPools/spark3p1sm",
				"name": "spark3p1sm",
				"type": "Spark",
				"endpoint": "https://bce-aae-oea-dev-syn.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark3p1sm",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.1",
				"nodeCount": 3,
				"cores": 8,
				"memory": 56,
				"automaticScaleJobs": true
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Microsoft Insights Class"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"class Insights(BaseOEAModule):\r\n",
					"    \"\"\"    Provides data processing methods for MS Insights data.\r\n",
					"    Data is expected to be received via ADS into stage1np/ms_insights\r\n",
					"    The structure of the folders in stage1np will then be something like:\r\n",
					"        -> stage1np/ms_insights/activity/2021-06-02\r\n",
					"            -> stage1np/ms_insights/activity/2021-06-02/ApplicationUsage.csv\r\n",
					"        -> stage1np/ms_insights/roster/2021-06-02T06-05-11/\r\n",
					"            -> stage1np/ms_insights/roster/2021-06-02T06-05-11/AadUser\r\n",
					"            -> stage1np/ms_insights/roster/2021-06-02T06-05-11/Person\r\n",
					"            etc\r\n",
					"\r\n",
					"    In stage2, everything is written to stage2np/ms_insights and stage2p/ms_insights\r\n",
					"    \"\"\"\r\n",
					"\r\n",
					"    def __init__(self, source_folder= 'SDS/M365'):\r\n",
					"        BaseOEAModule.__init__(self, source_folder)\r\n",
					"\r\n",
					"        self.stage1np_activity = self.stage1np + '/activity'\r\n",
					"        self.stage1np_roster = self.stage1np + '/roster'\r\n",
					"\r\n",
					"        self.schemas['TechActivity'] = [['SignalType', 'string', 'no-op'],\r\n",
					"                        ['StartTime', 'timestamp', 'no-op'],\r\n",
					"                        ['UserAgent', 'string', 'no-op'],\r\n",
					"                        ['SignalId', 'string', 'no-op'],\r\n",
					"                        ['SisClassId', 'string', 'no-op'],\r\n",
					"                        ['ClassId', 'string', 'no-op'],\r\n",
					"                        ['ChannelId', 'string', 'no-op'],\r\n",
					"                        ['AppName', 'string', 'no-op'],\r\n",
					"                        ['ActorId', 'string', 'hash-no-lookup'],\r\n",
					"                        ['ActorRole', 'string', 'no-op'],\r\n",
					"                        ['SchemaVersion', 'string', 'no-op'],\r\n",
					"                        ['AssignmentId', 'string', 'no-op'],\r\n",
					"                        ['SubmissionId', 'string', 'no-op'],\r\n",
					"                        ['SubmissionCreatedTime','timestamp','no-opt'], \r\n",
					"                        ['Action', 'string', 'no-op'],\r\n",
					"                        ['DueDate', 'timestamp', 'no-op'],\r\n",
					"                        ['ClassCreationDate', 'timestamp', 'no-op'],\r\n",
					"                        ['Grade', 'string', 'no-op'],\r\n",
					"                        ['SourceFileExtension', 'string', 'no-op'],\r\n",
					"                        ['MeetingDuration', 'string', 'no-op'], \r\n",
					"                        ['MeetingSessionId', 'string', 'no-op'],\r\n",
					"                        ['MeetingType', 'string','no-op' ],\r\n",
					"                        ['ReadingSubmissionWordsPerMinute','integer'      , 'no-op'],      \r\n",
					"                        ['ReadingSubmissionAccuracyScore',          'integer' , 'no-op'],     \r\n",
					"                        ['ReadingSubmissionMispronunciationsCount','integer' , 'no-op' ],      \r\n",
					"                        ['ReadingSubmissionRepetitionsCount','integer'       , 'no-op'   ],      \r\n",
					"                        ['ReadingSubmissionInsertionsCount','integer'       , 'no-op'   ],    \r\n",
					"                        ['ReadingSubmissionOmissionsCount','integer'       , 'no-op'   ],     \r\n",
					"                        ['ReadingSubmissionAttemptNumber','integer'       , 'no-op'   ],       \r\n",
					"                        ['ReadingAssignmentWordCount','integer'       , 'no-op'        ],      \r\n",
					"                        ['ReadingAssignmentFleschKincaidGradeLevel','integer'          , 'no-op' ],  \r\n",
					"                        ['ReadingAssignmentLanguage',           'string'        , 'no-op'  ],\r\n",
					"                        ['year', int, 'no-op'] ]\r\n",
					"\r\n",
					"        self.schemas['AadGroup'] = [['ObjectId', 'string', 'hash'],\r\n",
					"                        ['DisplayName', 'string', 'mask'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['LastSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['Mail', 'string', 'mask'],\r\n",
					"                        ['MailNickname', 'string', 'mask'],\r\n",
					"                        ['AnchorId', 'string', 'hash'],\r\n",
					"                        ['SectionId', 'string', 'no-op']]                           \r\n",
					"        self.schemas['AadGroupMembership'] = [['GroupObjectId', 'string', 'hash-no-lookup'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['LastSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['Role', 'string', 'no-op'],\r\n",
					"                        ['UserObjectId', 'string', 'hash-no-lookup']]  \r\n",
					"        self.schemas['AadUser'] = [['ObjectId', 'string', 'hash'],\r\n",
					"                        ['AnchorId', 'string', 'hash'],\r\n",
					"                        ['DisplayName', 'string', 'mask'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['GivenName', 'string', 'mask'],\r\n",
					"                        ['LastSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['Mail', 'string', 'mask'],\r\n",
					"                        ['MailNickname', 'string', 'mask'],\r\n",
					"                        ['Role', 'string', 'no-op'],\r\n",
					"                        ['Surname', 'string', 'mask'],\r\n",
					"                        ['UserPrincipalName', 'string', 'hash'],\r\n",
					"                        ['StudentId', 'string', 'hash-no-lookup'],\r\n",
					"                        ['TeacherId', 'string', 'hash-no-lookup']] \r\n",
					"        self.schemas['AadUserPersonMapping'] = [['ObjectId', 'string', 'hash-no-lookup'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['LastSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['PersonId', 'string', 'hash-no-lookup']] \r\n",
					"        self.schemas['Course'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['AcademicYearSessionId', 'string', 'no-op'],\r\n",
					"                        ['ExternalId', 'string', 'no-op'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['IsActiveInSession', 'boolean', 'no-op'],\r\n",
					"                        ['LastSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['Name', 'string', 'no-op'],\r\n",
					"                        ['OrganizationId', 'string', 'no-op'],\r\n",
					"                        ['SourceSystemId', 'string', 'no-op'],\r\n",
					"                        ['Code', 'string', 'no-op']] \r\n",
					"        self.schemas['CourseGradeLevel'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['CourseId', 'string', 'no-op'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['RefGradeLevelId', 'string', 'no-op']] \r\n",
					"        self.schemas['CourseSubject'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['CourseId', 'string', 'no-op'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['RefAcademicSubjectId', 'string', 'no-op']] \r\n",
					"        self.schemas['Enrollment'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['ExternalId', 'string', 'no-op'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['IsActiveInSession', 'boolean', 'no-op'],\r\n",
					"                        ['LastSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['PersonId', 'string', 'hash-no-lookup'],\r\n",
					"                        ['RefSectionRoleId', 'string', 'no-op'],\r\n",
					"                        ['SectionId', 'string', 'no-op'],\r\n",
					"                        ['SourceSystemId', 'string', 'no-op'],\r\n",
					"                        ['EntryDate', 'string', 'no-op'],\r\n",
					"                        ['ExitDate', 'string', 'no-op'],\r\n",
					"                        ['IsPrimaryStaffForSection', 'boolean', 'no-op']] \r\n",
					"        self.schemas['Organization'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['ExternalId', 'string', 'no-op'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['LastSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['Name', 'string', 'no-op'],\r\n",
					"                        ['RefOrganizationTypeId', 'string', 'no-op'],\r\n",
					"                        ['SourceSystemId', 'string', 'no-op'],\r\n",
					"                        ['Identifier', 'string', 'no-op'],\r\n",
					"                        ['ParentOrganizationId', 'string', 'no-op']] \r\n",
					"        self.schemas['Person'] = [['Id', 'string', 'hash'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['LastSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['GivenName', 'string', 'mask'],\r\n",
					"                        ['MiddleName', 'string', 'mask'],\r\n",
					"                        ['PreferredGivenName', 'string', 'mask'],\r\n",
					"                        ['PreferredMiddleName', 'string', 'mask'],\r\n",
					"                        ['PreferredSurname', 'string', 'mask'],\r\n",
					"                        ['Surname', 'string', 'mask']] \r\n",
					"        self.schemas['PersonDemographic'] = [['PersonId', 'string', 'hash'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['BirthCity', 'string', 'mask'],\r\n",
					"                        ['BirthCountryCode', 'string', 'mask'],\r\n",
					"                        ['BirthDate', 'string', 'mask'],\r\n",
					"                        ['BirthState', 'string', 'mask'],\r\n",
					"                        ['RefSexId', 'string', 'mask']] \r\n",
					"        self.schemas['PersonDemographicEthnicity'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['PersonId', 'string', 'hash-no-lookup'],\r\n",
					"                        ['RefEthnicityId', 'string', 'mask']] \r\n",
					"        self.schemas['PersonDemographicPersonFlag'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['PersonId', 'string', 'hash-no-lookup'],\r\n",
					"                        ['RefPersonFlagId', 'string', 'mask']] \r\n",
					"        self.schemas['PersonDemographicRace'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['PersonId', 'string', 'hash-no-lookup'],\r\n",
					"                        ['RefRaceId', 'string', 'mask']] \r\n",
					"        self.schemas['PersonEmailAddress'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['EmailAddress', 'string', 'mask'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['PersonId', 'string', 'hash-no-lookup'],\r\n",
					"                        ['PriorityOrder', 'short', 'no-op'],\r\n",
					"                        ['RefEmailAddressTypeId', 'string', 'no-op']] \r\n",
					"        self.schemas['PersonIdentifier'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['Identifier', 'string', 'mask'],\r\n",
					"                        ['IsPresentInSource', 'boolean', 'no-op'],\r\n",
					"                        ['PersonId', 'string', 'hash-no-lookup'],\r\n",
					"                        ['RefIdentifierTypeId', 'string', 'no-op'],\r\n",
					"                        ['SourceSystemId', 'string', 'no-op']] \r\n",
					"        self.schemas['PersonOrganizationRole'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['ExternalId', 'string', 'no-op'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['IsActiveInSession', 'boolean', 'no-op'],\r\n",
					"                        ['LastSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['OrganizationId', 'string', 'no-op'],\r\n",
					"                        ['PersonId', 'string', 'hash-no-lookup'],\r\n",
					"                        ['RefRoleId', 'string', 'no-op'],\r\n",
					"                        ['SessionId', 'string', 'no-op'],\r\n",
					"                        ['SourceSystemId', 'string', 'no-op'],\r\n",
					"                        ['IsPrimary', 'boolean', 'no-op'],\r\n",
					"                        ['RefGradeLevelId', 'string', 'no-op'],\r\n",
					"                        ['RoleEndDate', 'string', 'mask'],\r\n",
					"                        ['RoleStartDate', 'string', 'mask']] \r\n",
					"        self.schemas['PersonPhoneNumber'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['PersonId', 'string', 'hash-no-lookup'],\r\n",
					"                        ['PhoneNumber', 'string', 'mask'],\r\n",
					"                        ['PriorityOrder', 'short', 'no-op'],\r\n",
					"                        ['RefPhoneNumberTypeId', 'string', 'no-op']] \r\n",
					"        self.schemas['PersonRelationship'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['PersonId', 'string', 'hash-no-lookup'],\r\n",
					"                        ['RefPersonRelationshipId', 'string', 'no-op'],\r\n",
					"                        ['RelatedPersonId', 'string', 'hash-no-lookup']] \r\n",
					"        self.schemas['RefDefinition'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['Code', 'string', 'no-op'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['LastSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['Namespace', 'string', 'no-op'],\r\n",
					"                        ['RefType', 'string', 'no-op'],\r\n",
					"                        ['SortOrder', 'short', 'no-op']] \r\n",
					"        self.schemas['Section'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['ExternalId', 'string', 'no-op'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['LastSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['Name', 'string', 'no-op'],\r\n",
					"                        ['OrganizationId', 'string', 'no-op'],\r\n",
					"                        ['SourceSystemId', 'string', 'no-op'],\r\n",
					"                        ['Code', 'string', 'no-op'],\r\n",
					"                        ['CourseId', 'string', 'no-op'],\r\n",
					"                        ['Location', 'string', 'no-op']] \r\n",
					"        self.schemas['SectionGradeLevel'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['RefGradeLevelId', 'string', 'no-op'],\r\n",
					"                        ['SectionId', 'string', 'no-op']] \r\n",
					"        self.schemas['SectionSession'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['IsActiveInSession', 'boolean', 'no-op'],\r\n",
					"                        ['LastSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['SectionId', 'string', 'no-op'],\r\n",
					"                        ['SessionId', 'string', 'no-op']] \r\n",
					"        self.schemas['SectionSubject'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['RefAcademicSubjectId', 'string', 'no-op'],\r\n",
					"                        ['SectionId', 'string', 'no-op']] \r\n",
					"        self.schemas['Session'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['EndDate', 'string', 'no-op'],\r\n",
					"                        ['ExternalId', 'string', 'no-op'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['LastSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['Name', 'string', 'no-op'],\r\n",
					"                        ['RefAcademicYearId', 'string', 'no-op'],\r\n",
					"                        ['RefSessionTypeId', 'string', 'no-op'],\r\n",
					"                        ['SourceSystemId', 'string', 'no-op'],\r\n",
					"                        ['StartDate', 'string', 'no-op'],\r\n",
					"                        ['ParentSessionId', 'string', 'no-op']] \r\n",
					"        self.schemas['SourceSystem'] = [['Id', 'string', 'no-op'],\r\n",
					"                        ['FirstSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['LastSeenDateTime', 'timestamp', 'no-op'],\r\n",
					"                        ['Name', 'string', 'no-op']] \r\n",
					"    \r\n",
					"    def ingest(self):\r\n",
					"        \"\"\"  Processes insights data from stage1 into stage2 using structured streaming within the defined functions below.\"\"\"\r\n",
					"        logger.info(\"Processing microsoft_insights data from: \" + self.stage1np)\r\n",
					"        \r\n",
					"        items = mssparkutils.fs.ls(self.stage1np)\r\n",
					"        for item in items:\r\n",
					"            if item.name == \"activity\":\r\n",
					"                self.process_insights_activity_stage1_data()\r\n",
					"            elif item.name == \"roster\":\r\n",
					"                self.process_roster()\r\n",
					"            elif item.name == \"schemas\":\r\n",
					"                logger.info(\"ignoring ingestion of the schemas folder\")\r\n",
					"            elif item.name == \"current.manifest.cdm.json\":\r\n",
					"                logger.info(\"ignoring ingestion of the manifest json\")\r\n",
					"            else:\r\n",
					"                logger.info(\"No defined function for processing this insights data\")\r\n",
					"        \r\n",
					"        logger.info(\"Finished ingesting insights data from stage 1 to stage 2\")\r\n",
					"\r\n",
					"    def process_insights_activity_stage1_data(self, date_folder_files=None):\r\n",
					"        \"\"\" Processes activity data from stage1 into stage2 using structured streaming. \"\"\"\r\n",
					"        logger.info(\"Processing ms_insights activity data from: \" + self.stage1np_activity)\r\n",
					"\r\n",
					"        # Currently not using the OEA ingest_incremental_data function due to pulling out the partition folders\r\n",
					"        activity_spark_schema = oea.to_spark_schema(self.schemas['TechActivity'])\r\n",
					"\r\n",
					"        if date_folder_files is None: \r\n",
					"            date_folder_files = '/*/*.csv' \r\n",
					"        else:\r\n",
					"            date_folder_files= date_folder_files+'/*.csv'\r\n",
					"        \r\n",
					"        df = spark.readStream.csv(self.stage1np_activity + date_folder_files , header='false', schema=activity_spark_schema)\r\n",
					"        df = df.dropDuplicates(['SignalId'])\r\n",
					"        df = df.withColumn('year', F.year(F.col('StartTime'))).withColumn('month', F.month(F.col('StartTime')))\r\n",
					"\r\n",
					"        df_pseudo, df_lookup = oea.pseudonymize(df, self.schemas['TechActivity'])\r\n",
					"        #output complete only available with aggregations\r\n",
					"        if len(df_pseudo.columns) == 0:\r\n",
					"            logger.info('No data to be written to stage2p')\r\n",
					"        else:\r\n",
					"            query = df_pseudo.writeStream.format(\"delta\") \\\r\n",
					"                                         .outputMode(\"append\") \\\r\n",
					"                                         .option(\"checkpointLocation\", self.stage2p + '/_checkpoints/TechActivity_pseudo/') \\\r\n",
					"                                         .option(\"startingOffsets\", \"earliest\") \\\r\n",
					"                                         .option(\"truncate\", False) \\\r\n",
					"                                         .partitionBy('year')  \r\n",
					"            query = query.start(self.stage2p + '/TechActivity_pseudo')\r\n",
					"            query.awaitTermination()   # block until query is terminated, with stop() or with error; A StreamingQueryException will be thrown if an exception occurs.\r\n",
					"            logger.info(query.lastProgress)\r\n",
					"        \r\n",
					"        if len(df_lookup.columns) == 0:\r\n",
					"            logger.info('No data to be written to stage2np')\r\n",
					"        else:\r\n",
					"            query2 = df_lookup.writeStream.format(\"delta\") \\\r\n",
					"                              .outputMode(\"append\") \\\r\n",
					"                              .option(\"checkpointLocation\", self.stage2p + '/_checkpoints/TechActivity_lookup/') \\\r\n",
					"                              .option(\"startingOffsets\", \"earliest\") \\\r\n",
					"                              .option(\"truncate\", False) \\\r\n",
					"                              .partitionBy('year')\r\n",
					"            query2 = query2.start(self.stage2np + '/TechActivity_lookup')\r\n",
					"            query2.awaitTermination()   # block until query is terminated, with stop() or with error; A StreamingQueryException will be thrown if an exception occurs.\r\n",
					"            logger.info(query2.lastProgress)  \r\n",
					"\r\n",
					"    def full_load_insights_activity_stage1_data(self, date_folder_files=None):\r\n",
					"        \"\"\" Processes activity data from stage1 into stage2 using structured streaming. \"\"\"\r\n",
					"        logger.info(\"Processing ms_insights activity data from: \" + self.stage1np_activity)\r\n",
					"\r\n",
					"        # Currently not using the OEA ingest_incremental_data function due to pulling out the partition folders\r\n",
					"        activity_spark_schema = oea.to_spark_schema(self.schemas['TechActivity'])\r\n",
					"\r\n",
					"     \r\n",
					"        if date_folder_files is None: \r\n",
					"            date_folder_files = '/*/*.csv' \r\n",
					"        else:\r\n",
					"            date_folder_files= date_folder_files+'/*.csv'\r\n",
					"        \r\n",
					"        df = spark.read.csv(self.stage1np_activity + date_folder_files , header='false', schema=activity_spark_schema)\r\n",
					"        df = df.dropDuplicates(['SignalId'])\r\n",
					"        df = df.withColumn('year', F.year(F.col('StartTime'))).withColumn('month', F.month(F.col('StartTime')))\r\n",
					"\r\n",
					"        df_pseudo, df_lookup = oea.pseudonymize(df, self.schemas['TechActivity'])\r\n",
					"        #SignalId as Unique identifier for the Activities\r\n",
					"        mergeCondition = \"oldData.SignalId = newData.SignalId\"\r\n",
					"        Target= self.stage2np + '/TechActivity'\r\n",
					"        var_check = DeltaTable.isDeltaTable(spark,  Target)\r\n",
					"        try:\r\n",
					"            if (var_check):\r\n",
					"                print(\"Performing Merge... on Existing table\")\r\n",
					"\r\n",
					"                olddt = DeltaTable.forPath(spark, Target) \r\n",
					"\r\n",
					"                olddt.alias(\"oldData\").merge(\r\n",
					"                    df.alias(\"newData\"),\r\n",
					"                    mergeCondition) \\\r\n",
					"                .whenMatchedUpdateAll() \\\r\n",
					"                .whenNotMatchedInsertAll() \\\r\n",
					"                .execute()\r\n",
					"            else:\r\n",
					"                print(\"Creating new Delta Table.\")    \r\n",
					"                df.write.format(\"Delta\").save(Target)\r\n",
					"        except:\r\n",
					"            print(\"Table does not exist. Creating new Delta Table.\")    \r\n",
					"            df.write.format(\"Delta\").save(Target)\r\n",
					"\r\n",
					"\r\n",
					"    def returnDataFrameBeforeProcessing(self, tableName='TechActivity', sourcepath=''):\r\n",
					"        \"\"\" Processes activity data from stage1 into stage2 using structured streaming. \"\"\"\r\n",
					"        logger.info(\"Processing ms_insights activity data from: \" + sourcepath)\r\n",
					"        if sourcepath == '': \r\n",
					"            sourcepath=self.stage1np_activity\r\n",
					"        # Currently not using the OEA ingest_incremental_data function due to pulling out the partition folders\r\n",
					"        spark_schema = oea.to_spark_schema(self.schemas[f'{tableName}'])\r\n",
					"        df = spark.readStream.csv(sourcepath + '/*/*.csv', header='false', schema=spark_schema)\r\n",
					"\r\n",
					"        return df\r\n",
					"\r\n",
					"    def _process_roster_entity(self, path, entity):\r\n",
					"        try:\r\n",
					"            p_destination_path = self.stage2p + '/' + entity + '_pseudo'\r\n",
					"            np_destination_path = self.stage2np + '/' + entity + '_lookup'\r\n",
					"            source_path = path + '/' + entity\r\n",
					"            spark_schema = oea.to_spark_schema(self.schemas[entity])\r\n",
					"            df = spark.read.load(source_path, format='csv', header='false', schema=spark_schema)\r\n",
					"            df_pseudo, df_lookup = oea.pseudonymize(df, self.schemas[entity])\r\n",
					"\r\n",
					"            if len(df_pseudo.columns) == 0:\r\n",
					"                logger.info('No data to be written to stage2p')\r\n",
					"            else:\r\n",
					"                df_pseudo.write.save(p_destination_path, format='delta', mode='overwrite') \r\n",
					"\r\n",
					"            if len(df_lookup.columns) == 0:\r\n",
					"                logger.info('No data to be written to stage2np')\r\n",
					"            else:\r\n",
					"                df_lookup.write.save(np_destination_path, format='delta', mode='overwrite') \r\n",
					"\r\n",
					"        except (AnalysisException) as error:\r\n",
					"            logger.exception(str(error))\r\n",
					"\r\n",
					"\r\n",
					"    def _process_roster_date_folder(self, date_folder_path):\r\n",
					"        folders = oea.get_folders(date_folder_path)\r\n",
					"        for table_name in folders:\r\n",
					"            self._process_roster_entity(date_folder_path, table_name)\r\n",
					"            logger.info(\"Processing ms_insights roster snapshot data from: \" + source_path +'/'+table_name)\r\n",
					"\r\n",
					"\r\n",
					"    def process_roster(self):\r\n",
					"        \"\"\" Processes all roster data in stage1 and writes out to stage2 and stage2p \"\"\"\r\n",
					"  \r\n",
					"        latest_batch = oea.get_latest_folder(self.stage1np_roster)\r\n",
					"        source_path = self.stage1np_roster + '/' + latest_batch\r\n",
					"\r\n",
					"        self._process_roster_date_folder(source_path)\r\n",
					"  \r\n",
					"    def process_activity(self):\r\n",
					"        \"\"\" Processes all roster data in stage1 and writes out to stage2 and stage2p \"\"\"\r\n",
					"        logger.info(\"Processing ms_insights activity snapshot data from: \" + self.stage1np_activity)\r\n",
					"\r\n",
					"        latest_batch = oea.get_latest_folder(self.stage1np_activity)\r\n",
					"        source_path = self.stage1np_activity \r\n",
					"\r\n",
					"        folders = oea.get_folders(source_path)\r\n",
					"        for folder in folders:\r\n",
					"            self.process_insights_activity_stage1_data(folder)\r\n",
					"      "
				],
				"execution_count": 1
			}
		]
	}
}