{
	"name": "test",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "spark3p1sm",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "1ec2acfc-b960-4e3e-98eb-2b2bd65620b7"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/21fec1ab-7af8-4f99-b66f-a69e7ba77a22/resourceGroups/BCE-AAE-OEA-DEV-RG/providers/Microsoft.Synapse/workspaces/bce-aae-oea-dev-syn/bigDataPools/spark3p1sm",
				"name": "spark3p1sm",
				"type": "Spark",
				"endpoint": "https://bce-aae-oea-dev-syn.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark3p1sm",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.1",
				"nodeCount": 3,
				"cores": 8,
				"memory": 56,
				"automaticScaleJobs": true
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Test Class"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"source_folder= 'SDS/M365'\r\n",
					"storage_account = 'bceaaeoeadevlrs' "
				],
				"execution_count": 139
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from pyspark.sql.functions import *\r\n",
					"from pyspark.sql.window import Window\r\n",
					"\r\n",
					"# data lake and container information\r\n",
					"\r\n",
					"use_test_env = False\r\n",
					"\r\n",
					"if use_test_env:\r\n",
					"    stage1 = 'abfss://stage1@' + storage_account + '.dfs.core.windows.net/stage1'\r\n",
					"    stage2 = 'abfss://test-env@' + storage_account + '.dfs.core.windows.net/'\r\n",
					"    stage3 = 'abfss://test-env@' + storage_account + '.dfs.core.windows.net/'\r\n",
					"else:\r\n",
					"    stage1 = 'abfss://stage1@' + storage_account + '.dfs.core.windows.net'\r\n",
					"    stage2 = 'abfss://stage2@' + storage_account + '.dfs.core.windows.net'\r\n",
					"    stage3 = 'abfss://stage3@' + storage_account + '.dfs.core.windows.net'"
				],
				"execution_count": 140
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%run OEA_py"
				],
				"execution_count": 141
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"class test(BaseOEAModule):\r\n",
					"    \"\"\"    Provides data processing methods for MS Insights data.\r\n",
					"    Data is expected to be received via ADS into stage1np/ms_insights\r\n",
					"    The structure of the folders in stage1np will then be something like:\r\n",
					"        -> stage1np/example/test/*\r\n",
					"\r\n",
					"    In stage2, everything is written to stage2np/test and stage2p/test\r\n",
					"    \"\"\"\r\n",
					"\r\n",
					"    def __init__(self, source_folder= 'example/test'):\r\n",
					"        BaseOEAModule.__init__(self, source_folder)\r\n",
					"        self.stage1np_activity = self.stage1np + '/'\r\n",
					"        self.schemas['test'] = [['col', 'Integer', 'no-op']\r\n",
					"                    ]\r\n",
					"    \r\n",
					"    def ingest(self):\r\n",
					"        \"\"\"  Processes insights data from stage1 into stage2 using structured streaming within the defined functions below.\"\"\"\r\n",
					"        logger.info(\"Processing data from: \" + self.stage1np)\r\n",
					"        \r\n",
					"        items = mssparkutils.fs.ls(self.stage1np)\r\n",
					"        for item in items:\r\n",
					"            if item.name.__contains__(\"csv\"):\r\n",
					"                self.process_stage1_data()\r\n",
					"\r\n",
					"            else:\r\n",
					"                logger.info(\"No defined function for processing this insights data\")\r\n",
					"        \r\n",
					"        logger.info(\"Finished ingesting data from stage 1 to stage 2\")\r\n",
					"\r\n",
					"    def process_stage1_data(self):\r\n",
					"        \"\"\" Processes activity data from stage1 into stage2 using structured streaming. \"\"\"\r\n",
					"        logger.info(\"Processing test data from: \" + self.stage1np_activity)\r\n",
					"\r\n",
					"        # Currently not using the OEA ingest_incremental_data function due to pulling out the partition folders\r\n",
					"        activity_spark_schema = oea.to_spark_schema(self.schemas['test'])\r\n",
					"        df = spark.readStream.csv(self.stage1np_activity + '*.csv', header='false', schema=activity_spark_schema)\r\n",
					"        df = df.dropDuplicates(['col'])\r\n",
					"        \r\n",
					"       \r\n",
					"        df_pseudo, df_lookup = oea.pseudonymize(df, self.schemas['test'])\r\n",
					"\r\n",
					"        if len(df_pseudo.columns) == 0:\r\n",
					"            logger.info('No data to be written to stage2p')\r\n",
					"        else:\r\n",
					"            query = df_pseudo.writeStream.format(\"delta\").outputMode(\"append\").trigger(once=True).option(\"checkpointLocation\", self.stage1np_activity + '/_checkpoints_p')\r\n",
					"            query = query.start(self.stage2p + '')\r\n",
					"            query.awaitTermination()   # block until query is terminated, with stop() or with error; A StreamingQueryException will be thrown if an exception occurs.\r\n",
					"            logger.info(query.lastProgress)\r\n",
					"        \r\n",
					"        if len(df_lookup.columns) == 0:\r\n",
					"            logger.info('No data to be written to stage2np')\r\n",
					"        else:\r\n",
					"            query2 = df_lookup.writeStream.format(\"delta\").outputMode(\"append\").trigger(once=True).option(\"checkpointLocation\", self.stage1np_activity + '/_checkpoints_np')\r\n",
					"            query2 = query2.start(self.stage2np + '')\r\n",
					"            query2.awaitTermination()   # block until query is terminated, with stop() or with error; A StreamingQueryException will be thrown if an exception occurs.\r\n",
					"            logger.info(query2.lastProgress)   "
				],
				"execution_count": 142
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"oea= OEA()"
				],
				"execution_count": 143
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%run /Insights_py"
				],
				"execution_count": 144
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#test0= test()\r\n",
					"\r\n",
					"test= Insights()"
				],
				"execution_count": 145
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df= test.returnDataFrameBeforeProcessing('TechActivity')\r\n",
					""
				],
				"execution_count": 146
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#df.select('signalType', 'year', 'month')"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"test.stage2p"
				],
				"execution_count": 148
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#test.stage2np = stage2\r\n",
					"#test.stage2p = stage2\r\n",
					"#oea.stage2np = stage2\r\n",
					"#oea.stage2p = stage2\r\n",
					"\r\n",
					"oea.stage2p \r\n",
					"test.stage2p"
				],
				"execution_count": 149
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"source_path=   oea.stage1np +'/'+ source_folder +'/activity'\r\n",
					"\r\n",
					"source_path"
				],
				"execution_count": 150
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"spark_schema = oea.to_spark_schema(test.schemas['TechActivity'])"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#query = df.writeStream.format(\"delta\").outputMode(\"append\") \\\r\n",
					"#                                .option(\"checkpointLocation\", test.stage2p + '/_checkpoints/TechActivity_pseudo/') \\\r\n",
					"#                                .option(\"startingOffsets\", \"earliest\") \\\r\n",
					"#                                .option(\"truncate\", False).partitionBy('year')  \r\n",
					"#query = query.start(test.stage2p + '/TechActivity')\r\n",
					"#query.awaitTermination()   # block until query is terminated, with stop() or with error; A StreamingQueryException will be thrown if an exception occurs.\r\n",
					"#logger.info(query.lastProgress)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"source= test.stage1np_activity +'/*/*.csv'"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#df1 = spark.readStream.format(\"cloudFiles\").option(\"cloudFiles.format\", \"csv\").option(\"header\", \"false\").option( \"schema\",spark_schema).load(source)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#spark.readStream.format(\"cloudFiles\").option(\"cloudFiles.format\", \"csv\") \\\r\n",
					"  # The schema location directory keeps track of your data schema over time\r\n",
					" # .option(\"cloudFiles.schemaLocation\", \"<path-to-checkpoint>\").load(\"<path-to-source-data>\") \\\r\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Queries with streaming sources must be executed with writeStream.start();\r\n",
					"#display(df1)\r\n",
					"#df1.show()\r\n",
					"spark.catalog.listDatabases()\r\n",
					"\r\n",
					"#sqlContext.registerDataFrameAsTable(df, 'Activity')"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"spark.catalog.setCurrentDatabase('oea')"
				],
				"execution_count": 151
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"sqlContext.registerDataFrameAsTable(df, 'Activity')"
				],
				"execution_count": 134
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#oea.ingest_incremental_data( source_system=source_folder, tablename='Activity', schema=spark_schema, partition_by='year', primary_key='SignalId', data_format='csv', has_header=False)\r\n",
					"        "
				],
				"execution_count": 135
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"dfquery = spark.sql(\"select * from Activity where year = 2022 and SignalType = 'Call'\")"
				],
				"execution_count": 136
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#dfquery.show()"
				],
				"execution_count": 137
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"test.delete_stage2()"
				],
				"execution_count": 152
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#test.ingest()\r\n",
					"\r\n",
					"test.process_insights_activity_stage1_data()"
				],
				"execution_count": 154
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#test.delete_stage2()"
				],
				"execution_count": 32
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#test.process_activity()"
				],
				"execution_count": 50
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"db_name= 'bceoea'\r\n",
					"\r\n",
					"\r\n",
					"pathp  = test.stage2p\r\n",
					"pathnp = test.stage2np\r\n",
					"source_format= 'DELTA'\r\n",
					"\r\n",
					"print(pathp, pathnp)\r\n",
					""
				],
				"execution_count": 69
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"oea.create_sql_views(pathp, source_format)\r\n",
					""
				],
				"execution_count": 71
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"print (test.stage1np_activity)\r\n",
					"\r\n",
					"oea.get_folders(test.stage1np_activity)\r\n",
					"\r\n",
					"mssparkutils.fs.ls(test.stage1np)\r\n",
					"#pathnp = classSchool.stage2n"
				],
				"execution_count": 20
			}
		]
	}
}